---
---

@article{xia2024decipher,
  abbr={bioRxiv},
  title={High-fidelity disentangled cellular embeddings for large-scale heterogeneous spatial omics via DECIPHER},
  author={Chen-Rui*, Xia and Zhi-Jie*, Cao and Ge Gao†},
  journal={bioRxiv},
  year={2024},
  abstract={The functional role of a cell, shaped by the sophisticated interplay between its molecular identity and spatial context, is often obscured in current spatial modeling. Aiming to model large-scale heterogeneous spatial data in silico properly, DECIPHER produces high-fidelity disentangled embeddings, not only achieving superior performance in systematic benchmarks, but also empowering various real-world applications. We further demonstrated that DECIPHER is scalable to atlas-scale datasets, enabling global analysis which is largely infeasible to current state-of-the-arts.},
  html={https://www.biorxiv.org/content/10.1101/2024.11.29.626126v1},
  pdf={https://www.biorxiv.org/content/10.1101/2024.11.29.626126v1.full.pdf},
  publisher={Cold Spring Harbor Laboratory},
  selected={true}
}


@article{guo2024spatial,
  abbr={bioRxiv},
  title={Learning phenotype associated signature in spatial transcriptomics with PASSAGE},
  author={Chen-Kai*, Guo and Chen-Rui*, Xia and Guangdun Peng and Zhi-Jie, Cao and Ge Gao†},
  journal={bioRxiv},
  year={2024},
  abstract={Spatially resolved transcriptomics (SRT) is poised to advance our understanding of cellular organization within complex tissues under various physiological and pathological conditions at unprecedented resolution. Despite the development of numerous computational tools that facilitate the automatic identification of statistically significant intra-/inter-slice patterns (like spatial domains), these methods typically operate in an unsupervised manner, without leveraging sample characteristics like physiological/pathological states. Here we present PASSAGE (Phenotype Associated Spatial Signature Analysis with Graph-based Embedding), a rationally-designed deep learning framework for characterizing phenotype-associated signatures across multiple heterogeneous spatial slices effectively. In addition to its outstanding performance in systematic benchmarks, we have demonstrated PASSAGE’s unique capability in identifying sophisticated signatures in multiple real-world datasets. The full package of PASSAGE is available at https://github.com/gao-lab/PASSAGE.},
  html={https://www.biorxiv.org/content/10.1101/2024.09.06.611564v1},
  pdf={https://www.biorxiv.org/content/10.1101/2024.09.06.611564v1.full.pdf},
  publisher={Cold Spring Harbor Laboratory},
  selected={false}
}


@article{xia2023spatial,
  abbr={NatComm},
  title={Spatial-linked alignment tool (SLAT) for aligning heterogenous slices},
  author={Chen-Rui*, Xia and Zhi-Jie*, Cao and XinMing, Tu and Ge Gao†},
  journal={Nature Communications},
  volume={14},
  number={1},
  pages={7236},
  year={2023},
  abstract={Spatially resolved omics technologies reveal the spatial organization of cells in various biological systems. Here we propose SLAT (Spatially-Linked Alignment Tool), a graph-based algorithm for efficient and effective alignment of spatial slices. Adopting a graph adversarial matching strategy, SLAT is the first algorithm capable of aligning heterogenous spatial data across distinct technologies and modalities. Systematic benchmarks demonstrate SLAT's superior precision, robustness, and speed over existing state-of-the-arts. Applications to multiple real-world datasets further show SLAT's utility in enhancing cell-typing resolution, integrating multiple modalities for regulatory inference, and mapping fine-scale spatial-temporal changes during development. The full SLAT package is available at https://github.com/gao-lab/SLAT.},
  html={https://www.nature.com/articles/s41467-023-43105-5},
  pdf={https://www.nature.com/articles/s41467-023-43105-5.pdf},
  publisher={Nature Publishing Group UK London},
  selected={true},
  reward={Editors' Highlight}
}


@article{tu2022cross,
  abbr={NeurIPS},
  title={Cross-linked unified embedding for cross-modality representation learning},
  author={XinMing*, Tu and Zhi-Jie*, Cao and Chen-Rui, Xia and Sara Mostafavi† and Ge Gao†},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15942--15955},
  abstract={Multi-modal learning is essential for understanding information in the real world. Jointly learning from multi-modal data enables global integration of both shared and modality-specific information, but current strategies often fail when observa- tions from certain modalities are incomplete or missing for part of the subjects. To learn comprehensive representations based on such modality-incomplete data, we present a semi-supervised neural network model called CLUE (Cross-Linked Unified Embedding). Extending from multi-modal VAEs, CLUE introduces the use of cross-encoders to construct latent representations from modality-incomplete observations. Representation learning for modality-incomplete observations is common in genomics. For example, human cells are tightly regulated across multi- ple related but distinct modalities such as DNA, RNA, and protein, jointly defining a cell’s function. We benchmark CLUE on multi-modal data from single cell measurements, illustrating CLUE’s superior performance in all assessed categories of the NeurIPS 2021 Multimodal Single-cell Data Integration Competition. While we focus on analysis of single cell genomic datasets, we note that the proposed cross-linked embedding strategy could be readily applied to other cross-modality representation learning problems.},
  html={https://proceedings.neurips.cc/paper_files/paper/2022/hash/662b1774ba8845fc1fa3d1fc0177ceeb-Abstract-Conference.html},
  pdf={https://proceedings.neurips.cc/paper_files/paper/2022/file/662b1774ba8845fc1fa3d1fc0177ceeb-Paper-Conference.pdf},
  year={2022},
  selected={true},
  reward={Oral}
}